import numpy as np
import pandas as pd
import random as rd
import matplotlib.pyplot as plt
import json, datetime as dt

from sklearn import neighbors
from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.pipeline import Pipeline
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import (KNeighborsClassifier, NeighborhoodComponentsAnalysis)

from sklearn.decomposition import PCA
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from xgboost import plot_tree
from xgboost.sklearn import XGBClassifier
from scipy.spatial import distance

def categorical_conversion(df_input):
    for c in df_input.columns:
        if df_input[c].dtype == "object":
            df_input[c] = pd.Categorical(df_input[c])
            df_input[c] = df_input[c].cat.codes
    return df_input

print("Microsoft Malware Prediction using a KNN Algorithm")
d1 = dt.datetime.now()
print("Data processing started at", "%02d:%02d" % (d1.hour, d1.minute))

# Data loading
with open('data/json/datadtypes.json') as file:
    dtype = json.load(file)
filename = 'data/csv/train.csv'
n = 8921483 #number of records in file (excludes header)
sample_size = 200 #desired sample size
skip = sorted(rd.sample(range(1,n+1),n-sample_size)) #the 0-indexed header will not be included in the skip list
df = pd.read_csv(filename, dtype=dtype, skiprows=skip)

# categorical_cols=["AutoSampleOptIn", "Census_InternalBatteryNumberOfCharges", "Census_InternalBatteryType",
#     "Census_IsFlightingInternal", "Census_IsFlightsDisabled", "Census_IsWIMBootEnabled", "Census_ProcessorClass",
#     "Census_ThresholdOptIn", "DefaultBrowsersIdentifier", "IsBeta", "ProductName", "PuaMode", "UacLuaenable"]

# # columns with numerical values:
# numerical_cols = [
#     "Census_InternalPrimaryDiagonalDisplaySizeInInches", "Census_PrimaryDiskTotalCapacity",
#     "Census_ProcessorCoreCount", "Census_SystemVolumeTotalCapacity", "Census_TotalPhysicalRAM"]

# # columns with binary (0 or 1) values:
# binary_cols = [
#     "Census_HasOpticalDiskDrive", "Census_IsAlwaysOnAlwaysConnectedCapable", "Census_IsPenCapable",
#     "Census_IsPortableOperatingSystem", "Census_IsSecureBootEnabled", "Census_IsTouchEnabled",
#     "Census_IsVirtualDevice", "Firewall", "HasTpm", "IsProtected", "IsSxsPassiveMode", "SMode", "Wdft_IsGamer"]

numerical_cols = []
binary_cols = []
categorical_cols = []
for key, value in dtype.items():
    if value in ['int8']:
        binary_cols.append(key)
    if value in ['category']:
        categorical_cols.append(key)
    else:
        numerical_cols.append(key)
categorical_cols.remove('MachineIdentifier') # Déjà enlevé par iloc

# Cleaning NaN
for i in df.columns:
    s = df.loc[:, i]
    if i in numerical_cols:  # set NaNs in numerical features to -1
        s.fillna(-1, inplace=True)
    elif i in binary_cols:  # set NaNs in binary feature to the most frequent one
        s.fillna(s.mode().iloc[0], inplace=True)
    elif i in categorical_cols:
        s = s.cat.add_categories("unknown").fillna("unknown")
    df[i] = s.values
    if df[i].dtype == "int64" or df[i].dtype == "float64":
        df.loc[df[i].value_counts(normalize=True)[df[i]].values < 0.05, i] = -1

# df = categorical_conversion(df)  # convert data to categorical if the column dtype is "object"

class MultiColumnLabelEncoder:
    def __init__(self,columns = None):
        self.columns = columns # array of column names to encode

    def fit(self, X, y = None):
        return self # not relevant here

    def transform(self, X):
        output = X.copy()
        if self.columns is not None:
            for col in self.columns:
                output[col] = LabelEncoder().fit_transform(output[col])
        else:
            for colname,col in output.iteritems():
                output[colname] = LabelEncoder().fit_transform(col)
        return output

    def fit_transform(self, X, y = None):
        return self.fit(X, y).transform(X)

df = MultiColumnLabelEncoder(columns=list(categorical_cols)).fit_transform(df)
# df.to_csv('file_name.csv', index=False)

X = df.iloc[:,1:-1]
y = df.iloc[:,-1]
print (X.shape)
print (y.shape)

scaler = StandardScaler()
X=scaler.fit_transform(X)
pca = PCA()

#########
pca.fit_transform(X)
pca.get_covariance()
explained_variance=pca.explained_variance_ratio_
with plt.style.context('dark_background'):
    plt.figure(figsize=(6, 4))
    plt.bar(range(81), explained_variance, alpha=0.5, align='center',
            label='individual explained variance')
    plt.ylabel('Explained variance ratio')
    plt.xlabel('Principal components')
    plt.legend(loc='best')
    plt.tight_layout()
plt.show()
# print(sum(explained_variance[:16])) # 0.7303342511959455, only keep the first 15 components

##########
pca=PCA(n_components=15)
X_new=pca.fit_transform(X)
explained_variance=pca.explained_variance_ratio_
with plt.style.context('dark_background'):
    plt.figure(figsize=(6, 4))
    plt.bar(range(15), explained_variance, alpha=0.5, align='center',
            label='individual explained variance')
    plt.ylabel('Explained variance ratio')
    plt.xlabel('Principal components')
    plt.legend(loc='best')
    plt.tight_layout()
plt.show()



X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.2)
precision = []
for k in range(2,10):
    knn = neighbors.KNeighborsClassifier(k)
    precision.append(100*(knn.fit(X_train, y_train).score(X_test, y_test)))
d2 = dt.datetime.now()
print("Data processing ended at", "%02d:%02d" % (d2.hour, d2.minute))
plt.plot(range(2,10), precision, 'o-')
plt.show()





# knn1 = neighbors.KNeighborsClassifier(n_neighbors=9)
# knn1.fit(X_train, y_train)
# print('Precision rate: %f' % knn1.score(X_test, y_test))
