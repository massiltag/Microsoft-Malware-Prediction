import pickle
import pandas as pd
import numpy as np
import tensorflow as tf


def csv_to_pickled_converter():
    """
    convert csv data to pickle
    :return: nothing
    """
    df = pd.read_csv("../data/csv/test.csv")
    df.to_pickle("../data/pickled/test.pkl")
    print("test file converted")
    df = pd.read_csv("../data/csv/train.csv")
    df.to_pickle("../data/pickled/train.pkl")

    df = df.iloc[len(df)//4, :]
    df.to_pickle("../data/pickled/mini_train.pkl")
    print("train file converted")


def display_column_info():
    df = pd.read_pickle("../data/pickled/train.pkl")
    nb_entry = len(df.index)
    # bloqué à colonnes 8, 14, 15, 28, 29, 31, 41, 52, 53, 68 --> raison : colonne est "object"
    for i in range(69, len(df.columns)):
        temp = df.iloc[:, i]
        print("i:", i)
        if len(set(temp.tolist())) < 100:
            print("True")
            print(i, ")", df.columns[i], ": ", set(temp))
            print()
    print("\nFIN")


def get_dataset(file_path, LABEL_COLUMN, **kwargs):
    dataset = tf.data.experimental.make_csv_dataset(
        file_path,
        batch_size=5,  # Artificially small to make examples easier to show.
        label_name=LABEL_COLUMN,
        na_value="?",
        num_epochs=1,
        ignore_errors=True,
        **kwargs)
    return dataset


def categorical_conversion(df_input):
    """
    Convert to categorical instead of object
    Non categorical (non numeric, i.e. dtype = object) data need to be converted for TF 2.0 to works.
    Example : if a column has 3 possible values like Windows10, Windows7, WindowsXP, convert to 0, 1, 2

    """

    for i in df_input.columns:
        if df_input[i].dtype == "object":
            df_input[i] = pd.Categorical(df_input[i])
            df_input[i] = df_input[i].cat.codes

    return df_input


def get_compiled_model():
    model = tf.keras.Sequential([
        tf.keras.layers.Dense(10, activation='relu'),
        tf.keras.layers.Dense(10, activation='relu'),
        tf.keras.layers.Dense(1)
    ])

    model.compile(optimizer='adam',
    # model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),  # permet de changer le learning rate
                  loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),
                  metrics=['accuracy'])
    return model


if __name__ == '__main__':
    # execute this to convert to pickle for best performances. You need this for the code below to work
    # csv_to_pickled_converter()

    # display_column_info()      # execute this to display info about columns

    df = pd.read_pickle("../data/pickled/mini_train.pkl")  # read a smaller dataset so we can work faster
    df = categorical_conversion(df)  # convert data to categorical if the column dtype is "object"

    # Test : suppression des NaN par la median pour essayer de résoudre la loss = nan
    # supprime les colonnes avec + de 30% de NaN
    #                                                                                     > 60%                       > 30%
    df.drop(columns=["DefaultBrowsersIdentifier", "Census_IsFlightingInternal", "Census_ThresholdOptIn", "OrganizationIdentifier"], inplace=True)

    # affiche les colonnes où des NaN sont présents
    for i in df.columns:
        s = df.loc[:, i]
        if (s.isna().sum())/len(df) > 0:
            print("column ", i, ":", s.isna().sum(), " -->", ((s.isna().sum())/len(df))*100, "%, median =", s.median(skipna=True))

    exit(0)

    # remplace les NaN mar la médiane pour chaque colonne où des NaN sont présents
    for i in df.columns:
        s = df.loc[:, i]
        if s.isna().sum() != 0:
            series_median = s.median(skipna=True)
            df[i] = series_median

    # Création d'un réseau de neurones
    target = df.pop('HasDetections')
    tf.keras.backend.set_floatx('float64')  # utilise des float64 au lieu de 32
    dataset = tf.data.Dataset.from_tensor_slices((df.values, target.values))  # read the values from a pandas dataframe

    train_dataset = dataset.shuffle(len(df)).batch(1)  # shuffle and batch the dataset

    # train the model
    model = get_compiled_model()
    model.fit(train_dataset, epochs=15, use_multiprocessing=True)

