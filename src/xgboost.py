'''
    Microsoft Malware Prediction with XGBoost Decision Tree Algorithm
    Massil TAGUEMOUT
'''
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import json, datetime as dt

from sklearn.model_selection import train_test_split as tts
from xgboost.sklearn import XGBClassifier

print("Microsoft Malware Prediction using a Decision Tree Algorithm (XGBoost)")
d1 = dt.datetime.now()
print("Data processing started at", "%02d:%02d" % (d1.hour, d1.minute))

# Data loading
with open('./data/datatypes.json') as file:
    dtype = json.load(file)
df = pd.read_csv('../dcsv/microsoft-malware.csv', dtype=dtype)

# Dropping categorical
df = df.iloc[:20000,:]
binary = []
categorical = []
numerical = []

for key, value in dtype.items():
    if value in ['int8']:
        binary.append(key)
    if value in ['int16','category']:
        categorical.append(key)
    else:
        numerical.append(key)

categorical.remove('MachineIdentifier') # Déjà enlevé par iloc
df = df.drop(columns=list(categorical))


# Cleaning NaN
for i in df.columns:
    s = df.loc[:, i]
    if i in numerical:  # set NaNs in numerical features to -1
        s.fillna(-1, inplace=True)
    elif i in binary:  # set NaNs in binary feature to the most frequent one
        s.fillna(s.mode().iloc[0], inplace=True)
    df[i] = s.values
    if df[i].dtype == "int64" or df[i].dtype == "float64":
        df.loc[df[i].value_counts(normalize=True)[df[i]].values < 0.05, i] = -1



# Splitting dataset
data = df.iloc[:,1:-1] # Dropping MachineIdentifier & HasDetections
target = df.iloc[:,-1] # Selecting HasDetections
xtrain, xtest, ytrain, ytest = tts(data, target, train_size=0.8)


# Training model
boost = XGBClassifier(max_depth=4, n_estimators=500)
boost.fit(xtrain, ytrain)
boost_prediction = boost.predict(xtest)
print("Score Train :", round(boost.score(xtest, ytest)*100, 2), " %")
d2 = dt.datetime.now()
print("Took ", d2-d1)
